{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.master=\"yarn\"\n",
    "launcher.num_executors=6\n",
    "launcher.executor_memory=\"6000m\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.hadoop.mapreduce.lib.input.TextInputFormat\n",
    "import org.apache.hadoop.io.LongWritable\n",
    "import org.apache.hadoop.io.Text\n",
    "val conf = sc.hadoopConfiguration\n",
    "conf.set(\"textinputformat.record.delimiter\", \"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "val wikilinks=sc.newAPIHadoopFile(\"/hadoop-user/data/wikilinks.txt\", classOf[TextInputFormat],classOf[LongWritable], classOf[Text], conf)\n",
    ".map{case(offset,value)=>value.toString.trim()}\n",
    ".filter(value=>value.length!=0)\n",
    "\n",
    "\n",
    "def extractURLandMentions(rddelement:String):(String,Array[String])={\n",
    "    val splits=rddelement.split(\"\\n\")\n",
    "    var url=\"\"\n",
    "//var Mentions = collection.mutable.ArrayBuffer\n",
    "    var Mentions= Array[String]()\n",
    "    \n",
    "for(line<-splits)\n",
    "{\n",
    "    if(line.startsWith(\"URL\"))\n",
    "       {val splits=line.split(\"\\t\");\n",
    "      if (splits.length>=2) url=(splits(1))}\n",
    "    else if(line.startsWith(\"MENTION\"))\n",
    "    {\n",
    "        val splits=line.split(\"\\t\");\n",
    "       if(splits.length>=3) \n",
    "        Mentions:+=(splits(3))\n",
    "    }\n",
    "\n",
    "}\n",
    "   return(url,Mentions)\n",
    "}\n",
    "val logfile=wikilinks.map(rddelement=>extractURLandMentions(rddelement)).flatMapValues(rddelement=>rddelement)\n",
    "\n",
    "logfile.take(3).foreach(println)\n",
    "//The symmetric pair is 0 . So I have commented the code.\n",
    "//val URLA=logfile.map{case(url,mention)=>(mention,url)}\n",
    "//val joined= logfile.join(URLA)\n",
    "//joined.take(3).foreach(println)\n",
    "\n",
    "\n",
    "\n",
    "//finding the number of times each URL has been mentioned by another URL\n",
    "val counts=logfile.map{case(url1,url2)=>(url2,1)}.reduceByKey((url1,url2)=>url1+url2)\n",
    "\n",
    "counts.take(10).foreach(println)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "//logfile.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
